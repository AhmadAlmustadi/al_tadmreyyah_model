{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef8e64e4-6e85-44af-9f60-5d8ac1c6e4c1",
   "metadata": {},
   "source": [
    "### The goal of this relatively small notebook is to take a step in a larger project.\n",
    "\n",
    "Here, I am showing the results of the Grid Search applied to models trained on the texts from Al-Tadmoreyyah by Shaykh al-Islam Ibn Taymiyyah. This is part of a broader project aimed at training a model to become proficient in understanding and generating texts across all the works of Shaykh al-Islam.\n",
    "\n",
    "## Specific Objectives:\n",
    "*Show performance*: Display the performance of some of the best hyperparameter combinations from the grid search on Al-Tadmoreyyah.\n",
    "\n",
    "*Analyze changes*: Highlight how changes in the most critical hyperparameters affect the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6788b0-e13f-420d-b136-442c941c9659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "import os \n",
    "import re\n",
    "import shutil\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "981d40d8-623f-4335-8464-cc3414a37c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('al_tadmoreyyah_lr0.0002_bs2_wa0.0_ga2_r64_alpha128_dropout0.0',\n",
       " {'lr': [5e-05, 0.0002],\n",
       "  'bs': [8, 4, 2],\n",
       "  'wa': [0.01, 0.0],\n",
       "  'ga': [2],\n",
       "  'r': [32, 64],\n",
       "  'alpha': [64, 128],\n",
       "  'dropout': [0.0]})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_path = 'logs'\n",
    "\n",
    "\n",
    "hyper_dict = {'lr': [5e-5, 2e-4],\n",
    "              'bs': [8, 4, 2],\n",
    "              'wa': [0.01, 0.0],\n",
    "              'ga': [2],\n",
    "              'r': [32, 64],\n",
    "              'alpha': [64, 128],\n",
    "              'dropout': [0.0]}\n",
    "\n",
    "# السلسلة الأصلية التي نريد تعديلها\n",
    "fixed_para = 'al_tadmoreyyah_lr0.0002_bs2_wa0.0_ga2_r64_alpha128_dropout0.0'\n",
    "params = fixed_para.split('_')[2:]\n",
    "fixed_para, hyper_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e7ef6a-3219-428d-b52b-47f56350f87d",
   "metadata": {},
   "source": [
    "### Code Explanation\n",
    "\n",
    "This script is designed to generate variations of a given fixed parameter string (`fixed_para`) by modifying one parameter at a time based on a set of predefined values stored in `hyper_dict`. The goal is to change each parameter (like learning rate `lr`, batch size `bs`, etc.) to every possible value in the dictionary, while keeping the other parameters constant.\n",
    "\n",
    "#### Key Steps:\n",
    "\n",
    "1. **Extract Parameters:**\n",
    "   - The code first splits the `fixed_para` string to isolate each parameter and its corresponding value. For example, `lr0.0002` becomes `lr` and `0.0002`.\n",
    "\n",
    "2. **Avoid Repetition:**\n",
    "   - Before modifying a parameter, the code checks if the new value is the same as the current value in `fixed_para`. If it is, the code skips that value to avoid redundant combinations.\n",
    "\n",
    "3. **Generate Combinations:**\n",
    "   - For each parameter (e.g., `lr`, `bs`), the code loops over its possible values in `hyper_dict`. If the new value is different from the current one, it replaces the old value in `fixed_para` and stores the new string.\n",
    "\n",
    "4. **Output:**\n",
    "   - All unique combinations are printed and stored in a list called `combinations`. Each combination reflects the original string but with one parameter altered.\n",
    "\n",
    "This ensures that the script generates only valid, non-repetitive variations of the original string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49efa6a2-ab70-4f3b-b56d-8a6b95145603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All unique combinations generated:\n",
      "al_tadmoreyyah_lr5e-05_bs2_wa0.0_ga2_r64_alpha128_dropout0.0\n",
      "al_tadmoreyyah_lr0.0002_bs8_wa0.0_ga2_r64_alpha128_dropout0.0\n",
      "al_tadmoreyyah_lr0.0002_bs4_wa0.0_ga2_r64_alpha128_dropout0.0\n",
      "al_tadmoreyyah_lr0.0002_bs2_wa0.01_ga2_r64_alpha128_dropout0.0\n",
      "al_tadmoreyyah_lr0.0002_bs2_wa0.0_ga2_r32_alpha128_dropout0.0\n",
      "al_tadmoreyyah_lr0.0002_bs2_wa0.0_ga2_r64_alpha64_dropout0.0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "combinations = []\n",
    "\n",
    "# حلقة لتعديل قيمة معلمة واحدة في كل مرة\n",
    "for param in params:\n",
    "    # استخراج اسم المعلمة (مثل lr، bs، wa)\n",
    "    para = re.split(r'\\d+', param)[0]\n",
    "    \n",
    "    # القيمة الحالية لهذه المعلمة في السلسلة الأصلية\n",
    "    current_value = re.findall(r'\\d+\\.?\\d*', param)[0]\n",
    "    \n",
    "    # التأكد أن المعلمة موجودة في القاموس\n",
    "    if para in hyper_dict:\n",
    "        for value in hyper_dict[para]:\n",
    "            # التحقق إذا كانت القيمة الجديدة هي نفس القيمة الحالية\n",
    "            if str(value) == current_value:\n",
    "                continue  # تخطي إذا كانت القيمة متطابقة\n",
    "            \n",
    "            # تعديل السلسلة\n",
    "            # الجزء الأول قبل المعلمة\n",
    "            start = fixed_para.split(param)[0] + para + str(value)\n",
    "            # الجزء الأخير بعد المعلمة\n",
    "            last = fixed_para.split(param)[1]\n",
    "            # توليد السلسلة الجديدة\n",
    "            combination = start + last\n",
    "            # print('combination:', combination)\n",
    "            combinations.append(combination)\n",
    "\n",
    "# طباعة جميع التركيبات الممكنة\n",
    "print(\"\\nAll unique combinations generated:\")\n",
    "for combo in combinations:\n",
    "    print(combo)\n",
    "print(len(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39afd8d4-c2e2-463c-842c-9c9dad5131d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied F:\\language_model_project\\al_tadmorehhay_model\\logs\\al_tadmoreyyah_lr5e-05_bs2_wa0.0_ga2_r64_alpha128_dropout0.0 to F:\\language_model_project\\al_tadmorehhay_model\\test_hyper_parameters\\al_tadmoreyyah_lr5e-05_bs2_wa0.0_ga2_r64_alpha128_dropout0.0\n",
      "Copied F:\\language_model_project\\al_tadmorehhay_model\\logs\\al_tadmoreyyah_lr0.0002_bs8_wa0.0_ga2_r64_alpha128_dropout0.0 to F:\\language_model_project\\al_tadmorehhay_model\\test_hyper_parameters\\al_tadmoreyyah_lr0.0002_bs8_wa0.0_ga2_r64_alpha128_dropout0.0\n",
      "Copied F:\\language_model_project\\al_tadmorehhay_model\\logs\\al_tadmoreyyah_lr0.0002_bs4_wa0.0_ga2_r64_alpha128_dropout0.0 to F:\\language_model_project\\al_tadmorehhay_model\\test_hyper_parameters\\al_tadmoreyyah_lr0.0002_bs4_wa0.0_ga2_r64_alpha128_dropout0.0\n",
      "Copied F:\\language_model_project\\al_tadmorehhay_model\\logs\\al_tadmoreyyah_lr0.0002_bs2_wa0.01_ga2_r64_alpha128_dropout0.0 to F:\\language_model_project\\al_tadmorehhay_model\\test_hyper_parameters\\al_tadmoreyyah_lr0.0002_bs2_wa0.01_ga2_r64_alpha128_dropout0.0\n",
      "Copied F:\\language_model_project\\al_tadmorehhay_model\\logs\\al_tadmoreyyah_lr0.0002_bs2_wa0.0_ga2_r32_alpha128_dropout0.0 to F:\\language_model_project\\al_tadmorehhay_model\\test_hyper_parameters\\al_tadmoreyyah_lr0.0002_bs2_wa0.0_ga2_r32_alpha128_dropout0.0\n",
      "Copied F:\\language_model_project\\al_tadmorehhay_model\\logs\\al_tadmoreyyah_lr0.0002_bs2_wa0.0_ga2_r64_alpha64_dropout0.0 to F:\\language_model_project\\al_tadmorehhay_model\\test_hyper_parameters\\al_tadmoreyyah_lr0.0002_bs2_wa0.0_ga2_r64_alpha64_dropout0.0\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Destination directory\n",
    "destination = r'F:\\language_model_project\\al_tadmorehhay_model\\test_hyper_parameters'\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "# Loop through each directory and copy it to the destination\n",
    "for dir_path in combinations:\n",
    "    # Get the directory name from the path\n",
    "    dir_path = os.path.join(r'F:\\language_model_project\\al_tadmorehhay_model\\logs', dir_path)\n",
    "    dir_name = os.path.basename(dir_path)\n",
    "    # Form the full path in the destination\n",
    "    dest_dir = os.path.join(destination, dir_name)\n",
    "    \n",
    "    # Create the directory in the destination\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy the entire directory contents to the new directory\n",
    "    for item in os.listdir(dir_path):\n",
    "        s = os.path.join(dir_path, item)\n",
    "        d = os.path.join(dest_dir, item)\n",
    "        if os.path.isdir(s):\n",
    "            shutil.copytree(s, d)\n",
    "        else:\n",
    "            shutil.copy2(s, d)\n",
    "    \n",
    "    print(f\"Copied {dir_path} to {dest_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c7010309-b4d9-46a4-8c17-56b4d1851d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the idea here is to show you how does changing one of the critical hyperparamere effect the performance of the model\n",
    "# I check the original logs and came to conculoosion that this is the most critical ones.. \n",
    "# you can check the original logs (48 models) your self if you want..  \n",
    "%tensorboard --logdir test_hyper_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13fffeb-f0de-4931-aa41-33ff73ff882b",
   "metadata": {},
   "source": [
    "### Conclusion: Specialization of the Model for *Tadmuriyyah*\n",
    "\n",
    "Through iterative experimentation with hyperparameters, the model's ability to specialize in the *Tadmuriyyah* text has been significantly enhanced. By increasing the learning rate, alpha rank, and lower alpha, the model has demonstrated an improved capacity to internalize the unique linguistic and stylistic features of *Tadmuriyyah*. This strategic adjustment of hyperparameters has allowed the model to effectively overfit to the training data, capturing the intricate patterns present in the text.\n",
    "\n",
    "As a result, the model has evolved into a highly specialized tool, tailored specifically for *Tadmuriyyah*, offering more accurate predictions and better text generation that aligns closely with the distinct features of the book. These findings highlight the importance of fine-tuning hyperparameters to achieve a deep understanding of the text, making the model an invaluable resource for future analyses and applications related to *Tadmuriyyah*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3429e8b6-3862-4945-af38-dbc092cf8598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kill: 6006: No such process\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e2e8e586af79a798\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e2e8e586af79a798\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --port 6007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9757a10e-e41a-44d8-832a-e900e05f75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "the first notebook\n",
    "data extracting:\n",
    "## Introduction\n",
    "\n",
    "In this notebook, I am working with a classic Islamic text, *Al-Tadmuriyah* by Sheikh al-Islam Ibn Taymiyyah, which I have obtained from the Al-Shamila library in HTML format. The purpose of this notebook is to extract relevant text and information from this HTML file and then clean the data for further use. The extraction process will involve using Beautiful Soup to parse the HTML code, allowing me to retrieve important elements such as the text of the book, page numbers, and the book title.\n",
    "\n",
    "The data extracted from this text contains some inconsistencies and issues that must be addressed through data cleaning techniques. Once the data is cleaned and properly formatted, it will be saved as a CSV file. This cleaned data will later be uploaded to the Hugging Face datasets for further use in another notebook, where it will be fed into a large language model for analysis and exploration.\n",
    "\n",
    "This process is part of a broader project aimed at preserving and making accessible the writings of influential scholars in the digital age, particularly through the use of advanced natural language processing techniques.\n",
    "\n",
    "\n",
    "sec notebook building the base line model and then performing the grid search after seeing that the base line model performed really poorly:\n",
    "## Project Overview\n",
    "\n",
    "\n",
    "This project aims to fine-tune the AraGPT2-large model on classical Islamic texts, specifically focusing on the book Al-Tadmuriyah by Shaykh al-Islam Ibn Taymiyyah. The goal is to have the model become highly specialized in predicting and generating text within this specific book, even if it leads to overfitting. Overfitting is acceptable and even encouraged for this task, as the primary objective is for the model to accurately represent and generate the unique language style and content of *Al-Tadmuriyah*.\n",
    "\n",
    "\n",
    "To achieve this, I have followed these steps:\n",
    "\n",
    "1. Data Collection: The text of Al-Tadmuriyah was scraped and processed for training. The code used for this scraping can be found on my [GitHub repository](#), and the processed dataset is available on Hugging Face datasets for public access.\n",
    "   \n",
    "2. Model Selection: I used the AraGPT2-large model from Hugging Face, a powerful language model for Arabic. The model was quantized to 4-bit precision to reduce computational load while still retaining its performance potential.\n",
    "\n",
    "3. Training and Fine-Tuning: I trained the model for 50 epochs, initially observing poor performance. To address this, I performed a grid search over several hyperparameters to identify the best configuration for this task.\n",
    "\n",
    "4. Model Evaluation and Logs: The results from different configurations are logged and visualized using TensorBoard. All models generated from the grid search are available on my [Hugging Face repository](#).\n",
    "\n",
    "### What to Expect\n",
    "\n",
    "In this notebook, you will find:\n",
    "- Details on the data preparation process, including how the dataset was scraped and preprocessed.\n",
    "- The fine-tuning steps applied to AraGPT2-large on Al-Tadmuriyah.\n",
    "- A discussion of the initial training results, followed by the grid search for optimal hyperparameters.\n",
    "- Insights into the performance of the model across different configurations, along with links to the trained models.\n",
    "- Logs and visualizations of the training process using TensorBoard.\n",
    "\n",
    "\n",
    "\n",
    "third note book data vis:\n",
    "### The goal of this relatively small notebook is to take a step in a larger project.\n",
    "\n",
    "Here, I am showing the results of the Grid Search applied to models trained on the texts from Al-Tadmoreyyah by Shaykh al-Islam Ibn Taymiyyah. This is part of a broader project aimed at training a model to become proficient in understanding and generating texts across all the works of Shaykh al-Islam.\n",
    "\n",
    "## Specific Objectives:\n",
    "*Show performance*: Display the performance of some of the best hyperparameter combinations from the grid search on Al-Tadmoreyyah.\n",
    "\n",
    "*Analyze changes*: Highlight how changes in the most critical hyperparameters affect the model’s performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
